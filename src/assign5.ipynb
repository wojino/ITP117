{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gQFLDHZNmV1b"
      },
      "outputs": [],
      "source": [
        "import sklearn as s\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6kte4udnMQA",
        "outputId": "c9fb5dc1-49b6-4154-c73f-59d329ad95e8"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2FXQ-NVnrA5",
        "outputId": "373d2706-37e7-4f37-f7a0-aee0a5cfb42e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_full.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHYfIe40n6zu",
        "outputId": "b1a6c2db-36d2-4039-a44e-87b8ac126293"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_full.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fXmnxbFnn-8j"
      },
      "outputs": [],
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YoJwcsehs4Tp"
      },
      "outputs": [],
      "source": [
        "class_names=[\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy_TK2BAtaoG",
        "outputId": "032b36ff-f351-482c-db3d-3126c8227f59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a_r8p88xtd28",
        "outputId": "cbec7527-9ef6-4409-80ba-9f8d936ef029"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Coat'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_names[y_train[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6i87pCsut0s1"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
        "model.add(keras.layers.Dense(300,activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(100,activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(10,activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSFSbwZYgLcm",
        "outputId": "2a65ea5b-d5c6-40b0-9163-0d98456cdbd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBvZsm5ugT9n",
        "outputId": "62eb2ed2-6d65-444e-acdb-a6dc8476c2a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<keras.layers.core.flatten.Flatten at 0x196b4ec9f48>,\n",
              " <keras.layers.core.dense.Dense at 0x196b4ebd608>,\n",
              " <keras.layers.core.dense.Dense at 0x196d7c9e8c8>,\n",
              " <keras.layers.core.dense.Dense at 0x196d7ce2488>]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MB6LaI2QgXv9"
      },
      "outputs": [],
      "source": [
        "hidden1=model.layers[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9oaFRlvvgevI",
        "outputId": "5ca1fe0a-c9b7-415d-ab1f-81dca0ba1087"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'dense'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden1.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScDhgzLSgh_R",
        "outputId": "29ac01e9-007c-4c1c-ae52-0cf3870ba9ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_layer('dense') is hidden1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctRj5qT3gzGJ",
        "outputId": "5d5cffc4-665d-4d61-d6e7-130b7fb0a11d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.02606741, -0.01434201, -0.0027919 , ..., -0.00853626,\n",
              "        -0.02000209, -0.0201534 ],\n",
              "       [ 0.0149517 , -0.04920986,  0.04097205, ...,  0.07281232,\n",
              "        -0.07435453,  0.06844285],\n",
              "       [ 0.04069353, -0.03718376, -0.01652648, ...,  0.04324444,\n",
              "         0.06884713, -0.04487143],\n",
              "       ...,\n",
              "       [ 0.02327611, -0.01352863, -0.02969991, ..., -0.01396338,\n",
              "        -0.06431299,  0.00844902],\n",
              "       [-0.02061901,  0.00581837, -0.03665047, ...,  0.00829571,\n",
              "         0.04749186,  0.00092623],\n",
              "       [-0.02309696, -0.04106113, -0.02985428, ...,  0.04175003,\n",
              "         0.01678803, -0.0468138 ]], dtype=float32)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights, biases = hidden1.get_weights()\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1NWD6gAhB9d",
        "outputId": "f49231f0-d79a-4347-a0ff-3677001db6fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(784, 300)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH0avFLGhGL7",
        "outputId": "3a42aed0-b672-41d2-e599-a2612c617096"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ3z1alChKtS",
        "outputId": "aae26714-961e-4113-fa01-175131e365ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "biases.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "F4o3GGOMhunN"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhTd0fyliEFo",
        "outputId": "d3bf7e3c-d710-495c-ba92-f8e7171c77c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7283 - accuracy: 0.7640 - val_loss: 0.5091 - val_accuracy: 0.8306\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4920 - accuracy: 0.8295 - val_loss: 0.4606 - val_accuracy: 0.8450\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4462 - accuracy: 0.8451 - val_loss: 0.4660 - val_accuracy: 0.8390\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4192 - accuracy: 0.8538 - val_loss: 0.3957 - val_accuracy: 0.8710\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3982 - accuracy: 0.8603 - val_loss: 0.3858 - val_accuracy: 0.8638\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3827 - accuracy: 0.8670 - val_loss: 0.3821 - val_accuracy: 0.8696\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3683 - accuracy: 0.8699 - val_loss: 0.3648 - val_accuracy: 0.8756\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3568 - accuracy: 0.8730 - val_loss: 0.3531 - val_accuracy: 0.8778\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3468 - accuracy: 0.8776 - val_loss: 0.3534 - val_accuracy: 0.8780\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3358 - accuracy: 0.8811 - val_loss: 0.3360 - val_accuracy: 0.8806\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3267 - accuracy: 0.8834 - val_loss: 0.3471 - val_accuracy: 0.8794\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3187 - accuracy: 0.8864 - val_loss: 0.3399 - val_accuracy: 0.8784\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3123 - accuracy: 0.8880 - val_loss: 0.3321 - val_accuracy: 0.8834\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3044 - accuracy: 0.8913 - val_loss: 0.3343 - val_accuracy: 0.8806\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2994 - accuracy: 0.8927 - val_loss: 0.3327 - val_accuracy: 0.8830\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2922 - accuracy: 0.8951 - val_loss: 0.3288 - val_accuracy: 0.8820\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2860 - accuracy: 0.8972 - val_loss: 0.3140 - val_accuracy: 0.8900\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2802 - accuracy: 0.8991 - val_loss: 0.3119 - val_accuracy: 0.8858\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2750 - accuracy: 0.9022 - val_loss: 0.3140 - val_accuracy: 0.8850\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2693 - accuracy: 0.9038 - val_loss: 0.3128 - val_accuracy: 0.8912\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2640 - accuracy: 0.9052 - val_loss: 0.3013 - val_accuracy: 0.8940\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2597 - accuracy: 0.9069 - val_loss: 0.3145 - val_accuracy: 0.8846\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2560 - accuracy: 0.9077 - val_loss: 0.2968 - val_accuracy: 0.8918\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2501 - accuracy: 0.9097 - val_loss: 0.3011 - val_accuracy: 0.8902\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2466 - accuracy: 0.9116 - val_loss: 0.2975 - val_accuracy: 0.8900\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2412 - accuracy: 0.9130 - val_loss: 0.3225 - val_accuracy: 0.8788\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2384 - accuracy: 0.9141 - val_loss: 0.2983 - val_accuracy: 0.8944\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2345 - accuracy: 0.9151 - val_loss: 0.2983 - val_accuracy: 0.8912\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2294 - accuracy: 0.9184 - val_loss: 0.3106 - val_accuracy: 0.8896\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2265 - accuracy: 0.9189 - val_loss: 0.2933 - val_accuracy: 0.8920\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid,y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "13RRg4QUinJ9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "bK7KqBDmi1gJ",
        "outputId": "00bb8737-809a-425c-f711-500b81b6dacb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGADHmV7jThM",
        "outputId": "6881494a-39f4-446e-e54f-dab9fdfe4447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 48.8809 - accuracy: 0.8650\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[48.88090515136719, 0.8650000095367432]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crg8aF3Rjaqj",
        "outputId": "801488b1-4416-4f57-ffbd-a62462c99c50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_new = X_test[:3]\n",
        "y_proba = model.predict(X_new)\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "03wEOtTLjxfh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([9, 2, 1], dtype=int64)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = y_proba.argmax(axis=1)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO46ICLykT6T",
        "outputId": "abfe352a-6e91-4e66-f452-0a8b93965fa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Ankle boot' 'Pullover' 'Trouser']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.array(class_names)[y_pred])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2qacpT3kd-A",
        "outputId": "ffd77d08-4a74-40bb-c58e-6d9ae465ed7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([9, 2, 1], dtype=uint8)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_new = y_test[:3]\n",
        "y_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiWmnNwKk-4W",
        "outputId": "62cb1748-13cd-4d77-dbb2-af77bcc3f2f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\genie\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype=np.int):\n",
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to C:\\Users\\genie\\scikit_learn_data\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "housing = fetch_california_housing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "X1Sf1zKQlW_O"
      },
      "outputs": [],
      "source": [
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,y_train_full)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc1oTC534s3Y",
        "outputId": "ebbfc14e-434a-47b0-db54-41bcf06b7401"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.8350 - val_loss: 2.8875\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.8211 - val_loss: 0.4720\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4610 - val_loss: 0.4159\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4281 - val_loss: 0.3954\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4521 - val_loss: 0.3977\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4064 - val_loss: 0.3812\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3974 - val_loss: 0.3866\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4002 - val_loss: 0.3945\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3867 - val_loss: 0.3708\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3843 - val_loss: 0.3595\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3770 - val_loss: 0.3683\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3777 - val_loss: 0.3551\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3703 - val_loss: 0.3535\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3692 - val_loss: 0.3460\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4028 - val_loss: 0.3540\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3735 - val_loss: 0.3493\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3605 - val_loss: 0.3533\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3605 - val_loss: 0.3444\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3545 - val_loss: 0.3437\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3534 - val_loss: 0.3394\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.3670\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.Sequential([keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]), keras.layers.Dense(1)])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid,y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "X_new = X_test[:3]\n",
        "y_pred = model.predict(X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "EUHwdoYJ6OLp"
      },
      "outputs": [],
      "source": [
        "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.Concatenate()([input_,hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.Model(inputs=[input_], outputs=[output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "AQHLThPb7qOb"
      },
      "outputs": [],
      "source": [
        "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
        "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A,hidden2])\n",
        "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
        "model = keras.Model(inputs=[input_A,input_B], outputs=[output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRTqdR9O800L",
        "outputId": "60a619dd-28be-4027-9cde-a191e56ee212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\genie\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "363/363 [==============================] - 1s 2ms/step - loss: 2.0061 - val_loss: 0.9773\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.8093 - val_loss: 0.6984\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6800 - val_loss: 0.6477\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6375 - val_loss: 0.6099\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6116 - val_loss: 0.5932\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5926 - val_loss: 0.5698\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5764 - val_loss: 0.5512\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5629 - val_loss: 0.5415\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5505 - val_loss: 0.5412\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5398 - val_loss: 0.5248\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5297 - val_loss: 0.5056\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5202 - val_loss: 0.4985\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5115 - val_loss: 0.5012\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5036 - val_loss: 0.4867\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4956 - val_loss: 0.4703\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4887 - val_loss: 0.4631\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4823 - val_loss: 0.4578\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4767 - val_loss: 0.4536\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4714 - val_loss: 0.4468\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4668 - val_loss: 0.4412\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.4820\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"mse\",optimizer=keras.optimizers.SGD(lr=1e-3))\n",
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
        "history = model.fit((X_train_A, X_train_B), y_train, epochs=20, validation_data=((X_valid_A, X_valid_B), y_valid))\n",
        "mse_test = model.evaluate((X_test_A, X_test_B),y_test)\n",
        "y_pred = model.predict((X_new_A, X_new_B))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "IXOBeyOEUq8p"
      },
      "outputs": [],
      "source": [
        "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
        "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
        "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6adA12oVVLIl",
        "outputId": "7571ecf3-801d-4d95-97d6-a897b152f0e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.8214 - main_output_loss: 0.7317 - aux_output_loss: 1.6285 - val_loss: 1.7399 - val_main_output_loss: 1.8149 - val_aux_output_loss: 1.0653\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.6404 - main_output_loss: 0.6003 - aux_output_loss: 1.0016 - val_loss: 0.4844 - val_main_output_loss: 0.4417 - val_aux_output_loss: 0.8689\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5030 - main_output_loss: 0.4658 - aux_output_loss: 0.8377 - val_loss: 0.4543 - val_main_output_loss: 0.4227 - val_aux_output_loss: 0.7391\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4702 - main_output_loss: 0.4412 - aux_output_loss: 0.7314 - val_loss: 0.4457 - val_main_output_loss: 0.4208 - val_aux_output_loss: 0.6696\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4485 - main_output_loss: 0.4239 - aux_output_loss: 0.6704 - val_loss: 0.4212 - val_main_output_loss: 0.3991 - val_aux_output_loss: 0.6204\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4361 - main_output_loss: 0.4142 - aux_output_loss: 0.6326 - val_loss: 0.4079 - val_main_output_loss: 0.3869 - val_aux_output_loss: 0.5968\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4259 - main_output_loss: 0.4059 - aux_output_loss: 0.6052 - val_loss: 0.4042 - val_main_output_loss: 0.3849 - val_aux_output_loss: 0.5772\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4173 - main_output_loss: 0.3983 - aux_output_loss: 0.5878 - val_loss: 0.3983 - val_main_output_loss: 0.3801 - val_aux_output_loss: 0.5629\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4125 - main_output_loss: 0.3946 - aux_output_loss: 0.5736 - val_loss: 0.3924 - val_main_output_loss: 0.3747 - val_aux_output_loss: 0.5517\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4016 - main_output_loss: 0.3842 - aux_output_loss: 0.5582 - val_loss: 0.3882 - val_main_output_loss: 0.3718 - val_aux_output_loss: 0.5360\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4007 - main_output_loss: 0.3845 - aux_output_loss: 0.5459 - val_loss: 0.3754 - val_main_output_loss: 0.3588 - val_aux_output_loss: 0.5249\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3894 - main_output_loss: 0.3734 - aux_output_loss: 0.5331 - val_loss: 0.3799 - val_main_output_loss: 0.3649 - val_aux_output_loss: 0.5146\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3828 - main_output_loss: 0.3673 - aux_output_loss: 0.5224 - val_loss: 0.3659 - val_main_output_loss: 0.3508 - val_aux_output_loss: 0.5017\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3845 - main_output_loss: 0.3702 - aux_output_loss: 0.5129 - val_loss: 0.3774 - val_main_output_loss: 0.3638 - val_aux_output_loss: 0.4990\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3749 - main_output_loss: 0.3606 - aux_output_loss: 0.5039 - val_loss: 0.3690 - val_main_output_loss: 0.3560 - val_aux_output_loss: 0.4862\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3694 - main_output_loss: 0.3558 - aux_output_loss: 0.4919 - val_loss: 0.3476 - val_main_output_loss: 0.3337 - val_aux_output_loss: 0.4722\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3657 - main_output_loss: 0.3525 - aux_output_loss: 0.4846 - val_loss: 0.3595 - val_main_output_loss: 0.3473 - val_aux_output_loss: 0.4695\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3601 - main_output_loss: 0.3470 - aux_output_loss: 0.4782 - val_loss: 0.3514 - val_main_output_loss: 0.3383 - val_aux_output_loss: 0.4692\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3598 - main_output_loss: 0.3471 - aux_output_loss: 0.4740 - val_loss: 0.3475 - val_main_output_loss: 0.3349 - val_aux_output_loss: 0.4610\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3555 - main_output_loss: 0.3432 - aux_output_loss: 0.4664 - val_loss: 0.3495 - val_main_output_loss: 0.3373 - val_aux_output_loss: 0.4593\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=[\"mse\",\"mse\"], loss_weights=[0.9,0.1], optimizer=\"sgd\")\n",
        "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2w-bw-3WAIe",
        "outputId": "cf0f7216-aa77-40eb-89e4-fde463982468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 0.3799 - main_output_loss: 0.3665 - aux_output_loss: 0.5006\n"
          ]
        }
      ],
      "source": [
        "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "J2amEzg-WOj_"
      },
      "outputs": [],
      "source": [
        "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WideAndDeepModel(keras.Model):\n",
        "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
        "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
        "        self.main_output = keras.layers.Dense(1) \n",
        "        self.aux_output = keras.layers.Dense(1)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        input_A, input_B = inputs \n",
        "        hidden1 = self.hidden1(input_B)\n",
        "        hidden2 = self.hidden2(hidden1)\n",
        "        concat = keras.layers.concatenate([input_A, hidden2])\n",
        "        main_output = self.main_output(concat) \n",
        "        aux_output = self.aux_output(hidden2)\n",
        "\n",
        "        return main_output, aux_output \n",
        "\n",
        "model = WideAndDeepModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7832 - val_loss: 0.6465\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.8112 - val_loss: 0.5506\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5001 - val_loss: 0.5077\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4535 - val_loss: 0.4906\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4467 - val_loss: 0.4845\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4330 - val_loss: 0.4689\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4218 - val_loss: 0.4606\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4184 - val_loss: 0.4542\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4107 - val_loss: 0.4479\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4100 - val_loss: 0.4445\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4012 - val_loss: 0.4391\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3960 - val_loss: 0.4337\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3917 - val_loss: 0.4293\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3923 - val_loss: 0.4305\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3854 - val_loss: 0.4227\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3823 - val_loss: 0.4282\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3793 - val_loss: 0.4159\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3823 - val_loss: 0.4187\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3867 - val_loss: 0.4189\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3759 - val_loss: 0.4131\n"
          ]
        }
      ],
      "source": [
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,  y_train_full)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)\n",
        "model = keras.models.Sequential([keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]), keras.layers.Dense(1)])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
        "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "model.save(\"my_keras_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model = keras.models.load_model(\"my_keras_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3713\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3793\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3750\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3763\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3777\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3636\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3637\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3602\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3636\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3561\n"
          ]
        }
      ],
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
        "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3528 - val_loss: 0.3876\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3450 - val_loss: 0.3851\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3415 - val_loss: 0.4615\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3501 - val_loss: 0.6503\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3422 - val_loss: 0.3867\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3380 - val_loss: 0.3831\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3408 - val_loss: 0.3795\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3411 - val_loss: 0.3842\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3380 - val_loss: 0.3745\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3506 - val_loss: 0.3853\n"
          ]
        }
      ],
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb])\n",
        "model = keras.models.load_model(\"my_keras_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3550 - val_loss: 0.3771\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3352 - val_loss: 0.3751\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3371 - val_loss: 0.3731\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3309 - val_loss: 0.3723\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3298 - val_loss: 0.3733\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3330 - val_loss: 0.3727\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3343 - val_loss: 0.3701\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3279 - val_loss: 0.3694\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3274 - val_loss: 0.3679\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3265 - val_loss: 0.3651\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3273 - val_loss: 0.3869\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3246 - val_loss: 0.3656\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3238 - val_loss: 0.3745\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3363 - val_loss: 0.3744\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3229 - val_loss: 0.3626\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3237 - val_loss: 0.3595\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3200 - val_loss: 0.3585\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3222 - val_loss: 0.3592\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3200 - val_loss: 0.3570\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3302 - val_loss: 0.4010\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3674\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3216 - val_loss: 0.3629\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3350 - val_loss: 0.3700\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3244 - val_loss: 0.3599\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3226 - val_loss: 0.3609\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3221 - val_loss: 0.3625\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3159 - val_loss: 0.3515\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3151 - val_loss: 0.3534\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3156 - val_loss: 0.3538\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3143 - val_loss: 0.4480\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3161 - val_loss: 0.3576\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3153 - val_loss: 0.3530\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3120 - val_loss: 0.3594\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3118 - val_loss: 0.3484\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3103 - val_loss: 0.3546\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3100 - val_loss: 0.3509\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3097 - val_loss: 0.3453\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3089 - val_loss: 0.3458\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3129 - val_loss: 0.3473\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3121 - val_loss: 0.3509\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3099 - val_loss: 0.3465\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3125 - val_loss: 0.3564\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3124 - val_loss: 0.3775\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3088 - val_loss: 0.3444\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3070 - val_loss: 0.3566\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3067 - val_loss: 0.3460\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3056 - val_loss: 0.3535\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3054 - val_loss: 0.3415\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3049 - val_loss: 0.3396\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3077 - val_loss: 0.3433\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3060 - val_loss: 0.3449\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3045 - val_loss: 0.3451\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3032 - val_loss: 0.3408\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3036 - val_loss: 0.3395\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3065 - val_loss: 0.3394\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3146 - val_loss: 0.3444\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3054 - val_loss: 0.3457\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3024 - val_loss: 0.3425\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3027 - val_loss: 0.3496\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3033 - val_loss: 0.3406\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3041 - val_loss: 0.3414\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3020 - val_loss: 0.3441\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3014 - val_loss: 0.3405\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3048 - val_loss: 0.3386\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3014 - val_loss: 0.3403\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3001 - val_loss: 0.3358\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3023 - val_loss: 0.3473\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3006 - val_loss: 0.3336\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3012 - val_loss: 0.3354\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3029 - val_loss: 0.3398\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3008 - val_loss: 0.3413\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2996 - val_loss: 0.3436\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2996 - val_loss: 0.3384\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2992 - val_loss: 0.3369\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2996 - val_loss: 0.3652\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2996 - val_loss: 0.3376\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3015 - val_loss: 0.3344\n",
            "Epoch 78/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3402 - val_loss: 0.3430\n"
          ]
        }
      ],
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb, early_stopping_cb])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
        "\n",
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3000 - val_loss: 0.3461\n",
            "Epoch 2/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3003 - val_loss: 0.3368\n",
            "Epoch 3/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3015 - val_loss: 0.3415\n",
            "Epoch 4/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3017 - val_loss: 0.3388\n",
            "Epoch 5/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2993 - val_loss: 0.3363\n",
            "Epoch 6/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3000 - val_loss: 0.3368\n",
            "Epoch 7/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3000 - val_loss: 0.3322\n",
            "Epoch 8/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2992 - val_loss: 0.3410\n",
            "Epoch 9/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3042 - val_loss: 0.3406\n",
            "Epoch 10/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2999 - val_loss: 0.3535\n",
            "Epoch 11/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3296 - val_loss: 0.3422\n",
            "Epoch 12/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3034 - val_loss: 0.3376\n",
            "Epoch 13/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3020 - val_loss: 0.3354\n",
            "Epoch 14/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2998 - val_loss: 0.3440\n",
            "Epoch 15/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2994 - val_loss: 0.3332\n",
            "Epoch 16/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2987 - val_loss: 0.3355\n",
            "Epoch 17/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2985 - val_loss: 0.3405\n",
            "Epoch 18/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2989 - val_loss: 0.3386\n",
            "Epoch 19/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2982 - val_loss: 0.3488\n",
            "Epoch 20/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2973 - val_loss: 0.3394\n",
            "Epoch 21/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2978 - val_loss: 0.3345\n",
            "Epoch 22/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2976 - val_loss: 0.3300\n",
            "Epoch 23/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2980 - val_loss: 0.3506\n",
            "Epoch 24/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2969 - val_loss: 0.3472\n",
            "Epoch 25/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2966 - val_loss: 0.3371\n",
            "Epoch 26/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2999 - val_loss: 0.3342\n",
            "Epoch 27/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3001 - val_loss: 0.3404\n",
            "Epoch 28/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2977 - val_loss: 0.3653\n",
            "Epoch 29/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2984 - val_loss: 0.3389\n",
            "Epoch 30/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2957 - val_loss: 0.3338\n"
          ]
        }
      ],
      "source": [
        "tensorboard_cb = keras. callbacks.TensorBoard(run_logdir)\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-f2141f534aa595d1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-f2141f534aa595d1\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tensorboard --logdir=./my_logs --port=6006"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=bool, numpy=False>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "test_logdir = get_run_logdir()\n",
        "writer = tf.summary.create_file_writer(test_logdir)\n",
        "with writer.as_default():\n",
        "  for step in range(1, 1000 + 1):\n",
        "    tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
        "    data = (np.random.rand(100) + 2) * step / 100\n",
        "    tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
        "    images = np.random.rand(2, 32, 32, 3)\n",
        "    tf.summary.image(\"my_images\", images * step / 1000, step=step)\n",
        "    texts = [\"The step is \" + str(step), \"Its square Is \" + str(step**2)]\n",
        "    tf.summary.text(\"my_text\", texts, step=step)\n",
        "    sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
        "    audio = tf.reshape(tf.cast (sine_wave, tf.float32), [1,-1,1]) \n",
        "tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 17608), started 0:00:07 ago. (Use '!kill 17608' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-5f6c2c82c774ff0a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-5f6c2c82c774ff0a\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tensorboard --logdir=./my_logs --port=6006"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "NO_BN_model = keras.models.Sequential()\n",
        "NO_BN_model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "NO_BN_model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
        "NO_BN_model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
        "NO_BN_model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "BN_model = keras.models.Sequential([keras.layers.Flatten(input_shape=[28, 28]),\n",
        "                                    keras.layers.BatchNormalization(),\n",
        "                                    keras.layers.Dense(300, activation=\"relu\"),\n",
        "                                    keras.layers.BatchNormalization(),\n",
        "                                    keras.layers.Dense(100, activation=\"relu\"),\n",
        "                                    keras.layers.BatchNormalization(),\n",
        "                                    keras.layers.Dense(10, activation=\"softmax\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('batch_normalization/gamma:0', True),\n",
              " ('batch_normalization/beta:0', True),\n",
              " ('batch_normalization/moving_mean:0', False),\n",
              " ('batch_normalization/moving_variance:0', False)]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bn1 = BN_model.layers[1]\n",
        "[(var.name, var.trainable) for var in bn1.variables]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\genie\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1719/1719 [==============================] - 4s 2ms/step - loss: 1.4650 - accuracy: 0.5863 - val_loss: 0.9974 - val_accuracy: 0.6936\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.8759 - accuracy: 0.7195 - val_loss: 0.7735 - val_accuracy: 0.7486\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7316 - accuracy: 0.7652 - val_loss: 0.6754 - val_accuracy: 0.7828\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6585 - accuracy: 0.7885 - val_loss: 0.6200 - val_accuracy: 0.7982\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6113 - accuracy: 0.8017 - val_loss: 0.5811 - val_accuracy: 0.8116\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5776 - accuracy: 0.8111 - val_loss: 0.5549 - val_accuracy: 0.8178\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5521 - accuracy: 0.8176 - val_loss: 0.5322 - val_accuracy: 0.8222\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5322 - accuracy: 0.8228 - val_loss: 0.5168 - val_accuracy: 0.8294\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5163 - accuracy: 0.8270 - val_loss: 0.5009 - val_accuracy: 0.8366\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5034 - accuracy: 0.8302 - val_loss: 0.4895 - val_accuracy: 0.8362\n"
          ]
        }
      ],
      "source": [
        "NO_BN_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                    optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "                    metrics=[\"accuracy\"])\n",
        "history = NO_BN_model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.8553 - accuracy: 0.7128 - val_loss: 0.5543 - val_accuracy: 0.8096\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5711 - accuracy: 0.8035 - val_loss: 0.4747 - val_accuracy: 0.8378\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5122 - accuracy: 0.8209 - val_loss: 0.4398 - val_accuracy: 0.8504\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4822 - accuracy: 0.8319 - val_loss: 0.4177 - val_accuracy: 0.8568\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4565 - accuracy: 0.8395 - val_loss: 0.4037 - val_accuracy: 0.8608\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4355 - accuracy: 0.8461 - val_loss: 0.3916 - val_accuracy: 0.8640\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4247 - accuracy: 0.8494 - val_loss: 0.3822 - val_accuracy: 0.8662\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4115 - accuracy: 0.8558 - val_loss: 0.3745 - val_accuracy: 0.8684\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3988 - accuracy: 0.8587 - val_loss: 0.3691 - val_accuracy: 0.8696\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3933 - accuracy: 0.8596 - val_loss: 0.3640 - val_accuracy: 0.8710\n"
          ]
        }
      ],
      "source": [
        "BN_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                 optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "                 metrics=[\"accuracy\"])\n",
        "history = BN_model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.8189\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.526557207107544, 0.8188999891281128]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NO_BN_model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8576\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.4004640579223633, 0.8575999736785889]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BN_model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "housing = fetch_california_housing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.4315 - val_loss: 1.3119\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.3143 - val_loss: 1.2893\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.2701 - val_loss: 1.2188\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.1656 - val_loss: 1.0695\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.9427 - val_loss: 0.7971\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6998 - val_loss: 0.6477\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6193 - val_loss: 0.6143\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5906 - val_loss: 0.5905\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5697 - val_loss: 0.5745\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5510 - val_loss: 0.5611\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5349 - val_loss: 0.5450\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5190 - val_loss: 0.5246\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5040 - val_loss: 0.5112\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4918 - val_loss: 0.4995\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4794 - val_loss: 0.4946\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4698 - val_loss: 0.4795\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4619 - val_loss: 0.4753\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4555 - val_loss: 0.4672\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4505 - val_loss: 0.4644\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4468 - val_loss: 0.4585\n"
          ]
        }
      ],
      "source": [
        "NO_BN_model = keras.models.Sequential([keras.layers.Dense(50, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "                                       keras.layers.Dense(20, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "                                       keras.layers.Dense(20, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "                                       keras.layers.Dense(1)])\n",
        "NO_BN_model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
        "history = NO_BN_model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.6235 - val_loss: 0.7980\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4775 - val_loss: 0.4939\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4555 - val_loss: 0.4245\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4433 - val_loss: 0.4147\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4337 - val_loss: 0.4232\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4259 - val_loss: 0.3876\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4140 - val_loss: 0.4052\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4111 - val_loss: 0.3802\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4118 - val_loss: 0.3781\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4163 - val_loss: 0.3794\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3995 - val_loss: 0.3816\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4022 - val_loss: 0.3753\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3924 - val_loss: 0.3819\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3860 - val_loss: 0.3643\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3933 - val_loss: 0.3678\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3825 - val_loss: 0.3714\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3834 - val_loss: 0.3735\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3834 - val_loss: 0.3594\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3812 - val_loss: 0.3777\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3849 - val_loss: 0.3578\n"
          ]
        }
      ],
      "source": [
        "BN_model = keras.models.Sequential([keras.layers.Dense(50, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "                                    keras.layers.BatchNormalization(),\n",
        "                                    keras.layers.Dense(20, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "                                    keras.layers.BatchNormalization(),\n",
        "                                    keras.layers.Dense(20, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
        "                                    keras.layers.BatchNormalization(),\n",
        "                                    keras.layers.Dense(1)])\n",
        "BN_model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
        "history = BN_model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 1ms/step - loss: 0.4182\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.41816672682762146"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NO_BN_model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 0.3254\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.3253711462020874"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BN_model.evaluate(X_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "aip2_assign6_20211303.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
